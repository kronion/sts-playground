{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572551e-206c-413c-8836-604b7a45f02e",
   "metadata": {
    "id": "4572551e-206c-413c-8836-604b7a45f02e"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WzIeiEaJO5YM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzIeiEaJO5YM",
    "outputId": "d2ae18bf-b3d0-4862-89b1-771188d89b54"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958899de-6838-490c-bf4c-35034c0444b5",
   "metadata": {
    "id": "958899de-6838-490c-bf4c-35034c0444b5"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac323227-8a6e-476d-bdff-7cdb2d708aef",
   "metadata": {
    "id": "ac323227-8a6e-476d-bdff-7cdb2d708aef"
   },
   "outputs": [],
   "source": [
    "from gym_sts.data.state_log_loader import StateLogLoader\n",
    "\n",
    "loader = StateLogLoader()\n",
    "\n",
    "data_url = '../gym-sts/out/states/states_20221106-233706.json.gz'\n",
    "\n",
    "with open(data_url, \"rb\") as url:\n",
    "    with gzip.GzipFile(fileobj=url, mode='r') as f:\n",
    "        loader.load_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1ad11-8c58-45e9-a98f-fa99763b0d4f",
   "metadata": {
    "id": "77c1ad11-8c58-45e9-a98f-fa99763b0d4f"
   },
   "outputs": [],
   "source": [
    "with open(\"state_log_loader_small.pkl.gz\", \"wb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f, mode='w') as f2:\n",
    "        pickle.dump(loader, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276313f-5e40-4f43-ad9c-3c04503623ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loader_state_data_dict.pkl.gz\", \"wb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f, mode='w') as f2:\n",
    "        pickle.dump(loader.state_data, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44430128-0477-4180-8209-7c42a0e8aaa1",
   "metadata": {
    "id": "44430128-0477-4180-8209-7c42a0e8aaa1"
   },
   "outputs": [],
   "source": [
    "with open(\"state_log_loader_small.pkl.gz\", \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f, mode='r') as f2:\n",
    "        loader = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563af148-a87c-44d6-9d48-c21b78281773",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loader_state_data_dict.pkl.gz\", \"rb\") as f:\n",
    "    with gzip.GzipFile(fileobj=f, mode='r') as f2:\n",
    "        loader_state_data_dict = pickle.load(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b96d6-2a9d-4fbb-b800-f2f5c6633d72",
   "metadata": {
    "id": "e87b96d6-2a9d-4fbb-b800-f2f5c6633d72"
   },
   "source": [
    "# Experiment 1 - Embedding Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbc9923-78f5-46f0-84e0-069b341eac68",
   "metadata": {
    "id": "0bbc9923-78f5-46f0-84e0-069b341eac68"
   },
   "outputs": [],
   "source": [
    "with open(\"../gym-sts/loader_state_data.npz\", \"rb\") as f:\n",
    "    with np.load(f) as fz:\n",
    "        for _, v in fz.items():\n",
    "            loader_state_data = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec66a93d-a38d-4a52-8df2-875b1e3f7fc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec66a93d-a38d-4a52-8df2-875b1e3f7fc1",
    "outputId": "bde8d658-8685-45f4-97c6-37b08b50b69e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 47233)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_state_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f751f6-9c4e-4653-8525-2bb324034823",
   "metadata": {
    "id": "15f751f6-9c4e-4653-8525-2bb324034823"
   },
   "outputs": [],
   "source": [
    "total_size = loader_state_data.shape[0]\n",
    "train_size = round(total_size * 0.8)\n",
    "train_set, val_set = torch.utils.data.random_split(np.array(loader_state_data).astype(np.float32), [train_size, total_size - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67af0b8-f341-4e39-930e-c43de22ef806",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b67af0b8-f341-4e39-930e-c43de22ef806",
    "outputId": "5843598f-2725-4d9d-9280-a9197234e563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f2a563a4c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d4031c-817f-4725-a0fd-1811ed276c75",
   "metadata": {
    "id": "50d4031c-817f-4725-a0fd-1811ed276c75"
   },
   "outputs": [],
   "source": [
    "LOSS_FN = nn.MSELoss()\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_inputs : int, latent_dim : int):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, latent_dim),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_inputs : int, latent_dim : int):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, num_inputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_inputs : int, latent_dim : int):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = Encoder(num_inputs, latent_dim)\n",
    "        self.decoder = Decoder(num_inputs, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        xhat = self.decoder(z)\n",
    "        return xhat\n",
    "\n",
    "class LinearAutoEncoder(nn.Module):\n",
    "    def __init__(self, num_inputs : int, latent_dim : int):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(num_inputs, latent_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(latent_dim, num_inputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        xhat = self.net(x)\n",
    "        return xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "jKm-z1LJmNHP",
   "metadata": {
    "id": "jKm-z1LJmNHP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of features that are all 0: 0.8525818813117947\n",
      "Proportion of features that are all 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24409/2617420712.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  dud_val_loss = LOSS_FN(torch.tensor(val_set), torch.tensor(np.repeat(dists.reshape((1,len(dists))), len(val_set), axis=0)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dud validation loss: 0.0836987930342024\n"
     ]
    }
   ],
   "source": [
    "dists = loader_state_data.sum(axis=0) / loader_state_data.shape[1]\n",
    "\n",
    "print(f\"Proportion of features that are all 0: {sum(dists == 0) / loader_state_data.shape[1]}\")\n",
    "print(f\"Proportion of features that are all 1: {sum(dists == 1) / loader_state_data.shape[1]}\")\n",
    "\n",
    "# Pretend we're running a model f(X) = constant\n",
    "dud_val_loss = LOSS_FN(torch.tensor(val_set), torch.tensor(np.repeat(dists.reshape((1,len(dists))), len(val_set), axis=0)))\n",
    "\n",
    "print(f\"Dud validation loss: {dud_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b9275a-c83b-48a4-90b3-dd1dff42f6cb",
   "metadata": {
    "id": "64b9275a-c83b-48a4-90b3-dd1dff42f6cb"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True, drop_last=True)\n",
    "input_dim = val_set[0].shape[0]\n",
    "auto_encoder = LinearAutoEncoder(num_inputs=input_dim, latent_dim=512)\n",
    "optimizer = torch.optim.Adam(auto_encoder.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=20, min_lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3078dae-5237-421f-b9cc-f2140bd7551a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3078dae-5237-421f-b9cc-f2140bd7551a",
    "outputId": "4e6a5434-1295-4ea7-93ae-445c75a1a1ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch: 40/40 loss: 0.014221844263374805\n",
      "Validation loss: 0.012453131377696991\n",
      "Epoch 1\n",
      "Batch: 40/40 loss: 0.0046832067891955385\n",
      "Validation loss: 0.004682841710746288\n",
      "Epoch 2\n",
      "Batch: 40/40 loss: 0.0047970125451684386\n",
      "Validation loss: 0.004653583746403456\n",
      "Epoch 3\n",
      "Batch: 2/40 loss: 0.004727833438664675\r"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "val_losses = []\n",
    "\n",
    "def train():\n",
    "    total_batches = len(data_loader)\n",
    "    for batch_num, batch in enumerate(data_loader):\n",
    "        loss = LOSS_FN(batch, auto_encoder.forward(batch))\n",
    "        loss.backward()\n",
    "        print(f\"Batch: {batch_num+1}/{total_batches} loss: {loss.double()}\", end=\"\\r\")\n",
    "        training_losses.append(float(loss))\n",
    "        optimizer.step()\n",
    "    val_loss = LOSS_FN(torch.tensor(val_set), auto_encoder.forward(torch.tensor(val_set)))\n",
    "    print(f\"\\nValidation loss: {val_loss}\")\n",
    "    val_losses.append(float(val_loss))\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea916c9-1ab5-43e0-b07d-23fe2a8f318e",
   "metadata": {
    "id": "bea916c9-1ab5-43e0-b07d-23fe2a8f318e"
   },
   "outputs": [],
   "source": [
    "val_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "gym_sts",
   "language": "python",
   "name": "gym_sts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
